---
title: "glaucoma"
author: "Alexey Tsvetkov"
output:
  html_document:
    fig_height: 8
    fig_width: 10
---

```{r}
library(e1071)
library(MASS)
library(lattice)
```

```{r}
data <- read.table("./data/GlaucomaMVF.txt", header=TRUE, comment.char="#")
```

Linear kernel
===

```{r}
tn.svm.linear <- tune(svm, Class ~ ., data=data, type="C-classification", kernel="linear", ranges=list(cost=2^(-10:10)))
tn.svm.linear
xyplot(tn.svm.linear$performances[, "error"] ~ log(tn.svm.linear$performances[, "cost"]), type="b")
```

Polynomial kernel
===
```{r}
tn.svm.polynomial <- tune(svm, Class ~ ., data=data, type="C-classification", kernel="polynomial", ranges=list(cost=2^(-10:10), degree=(1:5)))
tn.svm.polynomial
xyplot(tn.svm.polynomial$performances[, "error"] ~ log(tn.svm.polynomial$performances[, "cost"]), groups=tn.svm.polynomial$performances[, "degree"] , type="b", auto.key=list(title="degree", corner=c(0.95,1), lines=TRUE))
```

С coef0
===
```{r}
tn.svm.polynomial <- tune(svm, Class ~ ., data=data, type="C-classification", kernel="polynomial", ranges=list(cost=2^(-10:10), degree=(1:2), coef0=(5:10)))
tn.svm.polynomial
```

Radial kernel
===
```{r}
tn.svm.radial <- tune(svm, Class ~ ., data=data, type="C-classification", kernel="radial", ranges=list(cost=2^(-10:10), gamma=(2^(-5:5))/ncol(data)))
tn.svm.radial
xyplot(tn.svm.radial$performances[, "error"] ~ log(tn.svm.radial$performances[, "cost"]), groups=tn.svm.radial$performances[, "gamma"] , type="b", auto.key=list(title="gamma", corner=c(0.95,1), lines=TRUE))
plot(tn.svm.radial, transform.x=log, transform.y=log, color.palette=rainbow)
```

Оказалось, что линейное ядро работает лучше любых полиномиальных ядер с более высокими степенями.
Это говорит о том, что исходные данные хорошо разделимы линейно.
Радиальное ядро также не показало результатов превосходивших линейное ядро.
Ещё можно заметить, что при увеличении gamma результаты становятся хуже при равном значении cost.